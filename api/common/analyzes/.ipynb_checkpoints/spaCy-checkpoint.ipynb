{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from api.db import stat_db, crawl_db, CrawlCollections, StatCollections\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.matcher import Matcher\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'Apple is looking at buying U.K. startup for $1 billion')\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "          token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "doc = nlp(u'Autonomous cars shift insurance liability toward manufacturers')\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.root.dep_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "# add match ID \"HelloWorld\" with no callback and one pattern\n",
    "pattern = [{'LOWER': 'hello'}, {'IS_PUNCT': True}, {'LOWER': 'world'}]\n",
    "matcher.add('HelloWorld', None, pattern)\n",
    "\n",
    "doc = nlp(u'Hello, world! Hello world!')\n",
    "matches = matcher(doc)\n",
    "print(matches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the ID of the 'EVENT' entity type. This is required to set an entity.\n",
    "EVENT = nlp.vocab.strings['EVENT']\n",
    "\n",
    "\n",
    "def add_event_ent(matcher, doc, i, matches):\n",
    "    # Get the current match and create tuple of entity label, start and end.\n",
    "    # Append entity to the doc's entity. (Don't overwrite doc.ents!)\n",
    "    match_id, start, end = matches[i]\n",
    "    doc.ents += ((EVENT, start, end),)\n",
    "\n",
    "\n",
    "matcher.add('GoogleIO', add_event_ent,\n",
    "            [{'ORTH': 'Google'}, {'UPPER': 'I'}, {'ORTH': '/'}, {'UPPER': 'O'}],\n",
    "            [{'ORTH': 'Google'}, {'UPPER': 'I'}, {'ORTH': '/'}, {'UPPER': 'O'}, {'IS_DIGIT': True}])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_sents = [] # collect data of matched sentences to be visualized\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "def collect_sents(matcher, doc, i, matches):\n",
    "    match_id, start, end = matches[i]\n",
    "    span = doc[start : end] # matched span\n",
    "    sent = span.sent # sentence containing matched span\n",
    "    # append mock entity for match in displaCy style to matched_sents\n",
    "    # get the match span by ofsetting the start and end of the span with the\n",
    "    # start and end of the sentence in the doc\n",
    "    match_ents = [{'start': span.start_char - sent.start_char,\n",
    "                   'end': span.end_char - sent.start_char,\n",
    "                   'label': 'MATCH'}]\n",
    "    print(sent.text)\n",
    "    matched_sents.append({'text': sent.text, 'ents': match_ents })\n",
    "    \n",
    "\n",
    "pattern = [{'LOWER': 'facebook'}, {'LEMMA': 'be'}, {'POS': 'ADV', 'OP': '*'},\n",
    "           {'POS': 'ADJ'}]\n",
    "matcher.add('FacebookIs', collect_sents, pattern) # add pattern\n",
    "\n",
    "cursor = crawl_db[CrawlCollections.BTT_COMMENT].find({'data.link_id': '1883902'}).limit(10)\n",
    "for item in cursor:\n",
    "    text = item['data']['content'] \n",
    "    matches = matcher(nlp(text)) # match on your text\n",
    "    \n",
    "# serve visualization of sentences containing match with displaCy\n",
    "# set manual=True to make displaCy render straight from a dictionary\n",
    "displacy.serve(matched_sents, style='ent', manual=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
