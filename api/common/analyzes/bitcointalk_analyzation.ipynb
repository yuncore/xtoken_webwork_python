{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from api.db import stat_db, crawl_db, CrawlCollections, StatCollections, relation_db, RelationCollections, DESCENDING, ASCENDING\n",
    "import time\n",
    "import math\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "\n",
    "统计单个帖子评论数随时间的分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "comments = pd.DataFrame([item['data'] for item in crawl_db[CrawlCollections.BTT_COMMENT].find({'data.link_id': '2207367'})],\n",
    "                                columns=['time'])\n",
    "comments.time = comments['time'].apply(lambda x: datetime.fromtimestamp(x))\n",
    "comments.set_index(comments.time, inplace=True)\n",
    "comments['num'] = 1\n",
    "comments.drop('time', axis=1)\n",
    "temp = comments.resample('D').sum().fillna(0)\n",
    "temp.reset_index().to_json(orient='values')\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "\n",
    "统计一个关键词在数据库中出现的次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = crawl_db[CrawlCollections.BTT_COMMENT].find()\n",
    "select_comments = []\n",
    "for comment in comments:\n",
    "    try:\n",
    "        text = comment['data']['content']\n",
    "        if re.search(r'\\bsmart contract\\b', text, re.I) is not None:\n",
    "            select_comments.append(comment)\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "\n",
    "统计最先说出这个关键词的人等级分布以及随时间的分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame([item['data'] for item in select_comments], columns=['time', 'activity', 'author', 'link_id', 'user_id', 'grade'])\n",
    "df['num'] = 1\n",
    "group = df.groupby(['author', 'grade'], as_index=False)\n",
    "grouped_df = group.agg({'time': np.min, 'num': np.sum, 'activity': np.max})\n",
    "d = grouped_df['grade'].astype('category')\n",
    "grouped_df['time'] = grouped_df['time'] * 1000\n",
    "max = grouped_df['num'].max()\n",
    "min = grouped_df['num'].min()\n",
    "grouped_df['num'] = grouped_df['num'].map(lambda x: np.floor((x - min) / (max - min) * 48 + 2))\n",
    "activity = grouped_df['activity']\n",
    "time = grouped_df['time']\n",
    "grouped_df.drop(labels=['activity'], axis=1,inplace=True)\n",
    "grouped_df.drop(labels=['time'], axis=1,inplace = True)\n",
    "grouped_df.insert(0, 'activity', activity)\n",
    "grouped_df.insert(0, 'time', time)\n",
    "top30 = grouped_df.sort_values(by='time')[:30]\n",
    "top30_json = top30.to_json(orient='values')\n",
    "json_arr = []\n",
    "for grade in d.cat.categories:\n",
    "    df = grouped_df[grouped_df['grade'] == grade]\n",
    "    json = df.to_json(orient='values')\n",
    "    json_arr.append({'data': json, 'grade': grade})   \n",
    "\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "统计这些词在项目中的分布数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([item['data'] for item in select_comments], columns=['time', 'link_id'])\n",
    "relation_btt = relation_db[RelationCollections.RELATION_CURRENCY_BTT].find({'ann': True})\n",
    "link_replies = []\n",
    "for item in relation_btt:\n",
    "    link = crawl_db[CrawlCollections.BTT_LINK].find_one({'data.id': item['topic_id']})\n",
    "    if link is not None:\n",
    "        link_replies.append({'topic_id': link['data']['id'], 'replies': link['data']['replies'], 'currency_name': item['currency_name']})\n",
    "df2 = pd.DataFrame([item for item in link_replies], columns=['currency_name', 'topic_id', 'replies'])\n",
    "df2['num'] = 1\n",
    "merge_df = pd.merge(df, df2, how='left', left_on='link_id', right_on='topic_id')\n",
    "\n",
    "\n",
    "merge_df2 = merge_df.dropna()\n",
    "\n",
    "grouped_df = merge_df2.groupby(['currency_name', 'link_id']).agg({'time': np.min, 'num': np.sum, 'replies': np.max})\n",
    "\n",
    "grouped_df2 = grouped_df.reset_index()\n",
    "grouped_df2.head()\n",
    "json_arr2 = grouped_df2.to_json(orient='values') \n",
    "stat_db[\"btt_keyword_stat\"].find_one_and_update({'keyword': 'smart contract'},\n",
    "                                                {'$set': {'project_data': json_arr2}},\n",
    "                                                upsert=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "relation_btt = relation_db[RelationCollections.RELATION_CURRENCY_BTT].find({'ann': True})\n",
    "relation_df = pd.DataFrame([item for item in relation_btt], columns=['topic_id', 'currency_name'])\n",
    "\n",
    "# 获取数据库中所有的用户\n",
    "user_list = crawl_db[CrawlCollections.BTT_COMMENT].aggregate([{'$group': {'_id': '$data.user_id'}}])\n",
    "for user in user_list:\n",
    "    user_id = user['_id']\n",
    "\n",
    "    # 从数据库中查找用户分析过的数据，如果不为空则跳出循环\n",
    "    stat_data = stat_db[StatCollections.BTT_USER_HISTORY_STAT].find_one({'_id': user_id})\n",
    "    if stat_data is not None:\n",
    "        break\n",
    "\n",
    "    # 从数据库中加载该用户的所有评论\n",
    "    df = pd.DataFrame(\n",
    "        [item['data'] for item in crawl_db[CrawlCollections.BTT_COMMENT].find({'data.user_id': user_id})],\n",
    "        columns=['time', 'author', 'user_id', 'link_id'])\n",
    "\n",
    "    # 将关系data frame和\n",
    "    merged_df = pd.merge(df, relation_df, left_on='link_id', right_on='topic_id', how='left')\n",
    "    clean_merged_df = merged_df.dropna().drop('topic_id', axis=1)\n",
    "\n",
    "    # 将数据按照currency name分组，获取每个currency的评论数量\n",
    "    clean_merged_df['num'] = 1\n",
    "    grouped_df = clean_merged_df.groupby(['link_id', 'currency_name'], as_index=False).agg({'num': np.sum})\n",
    "    general_data = grouped_df.to_json(orient='values')\n",
    "\n",
    "    # 将用户的足迹按照currency name 分类, 获取评论分布图\n",
    "    arr_data = []\n",
    "    clean_merged_df['time'] = clean_merged_df['time'].apply(lambda x: datetime.fromtimestamp(x))\n",
    "    clean_merged_df.set_index(clean_merged_df.time, inplace=True)\n",
    "    clean_merged_df.drop('time', axis=1)\n",
    "    d = clean_merged_df['currency_name'].astype('category')\n",
    "    for currency_name in d.cat.categories:\n",
    "        temp_df = clean_merged_df[clean_merged_df['currency_name'] == currency_name]\n",
    "        resampled_df = temp_df.resample('D').sum().fillna(0)\n",
    "        json_data = resampled_df.reset_index().to_json(orient='values')\n",
    "        arr_data.append({currency_name: json_data})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 找到btt中评论最多的前100人\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "user_list = crawl_db[CrawlCollections.BTT_COMMENT].aggregate([{'$group': {'_id': '$data.user_id', 'num': {'$sum': 1}}}])\n",
    "user_df = pd.DataFrame([item for item in user_list], columns=['_id', 'num'])\n",
    "user_df = user_df.sort_values(by='num', ascending=False)[:100]\n",
    "for index, row in user_df.iterrows():\n",
    "    stat_db['btt_kol'].find_one_and_update({'_id': row['_id']}, {'$set': {'user_id': row['_id'], 'num': row['num']}}, upsert=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 按照时间点分析btt的评论情况\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 1447084800\n",
    "one_day = 3600 * 24\n",
    "\n",
    "cs = crawl_db[CrawlCollections.BTT_COMMENT].find({'data.time': {'$gte': t, '$lte': t+one_day}})\n",
    "df = pd.DataFrame([i[''] for i in cs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawl_db[RelationCollections.RELATION_CURRENCY_BTT].find()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
